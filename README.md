# NextTick6 - Trading System

Ein fortschrittliches System zur Analyse von Handelsdaten und Generierung von Handelssignalen mit maschinellem Lernen.

## ğŸ”„ Projekt-Pipeline (Phasen)

1. ğŸ“¥ **Datenbeschaffung** â€“ Laden von Yahoo Finance-Daten (`yfinance`)
2. ğŸ§® **Feature Engineering** â€“ Berechnung technischer Indikatoren (`ta`)
3. ğŸ”§ **Preprocessing** â€“ Normalisierung, Sequenzierung
4. ğŸ¤– **Modelltraining** â€“ LSTM-Vorhersage-Modell (`keras`/`torch`)
5. ğŸ“Š **Evaluation** â€“ Testdaten-Auswertung
6. ğŸ“ˆ **Signal-Generierung** â€“ Buy/Sell-Logik aus Vorhersagen
7. ğŸ¨ **Visualisierung** â€“ Preis, Vorhersage & Signale
8. ğŸ§ª **Backtest** â€“ Simulierter Handel mit Ergebnisanalyse
9. ğŸ’¾ **Export** â€“ Modell & Ergebnisse speichern

## ğŸ“ Projektstruktur

Die detaillierte Projektstruktur finden Sie in der [project_structure.md](./project_structure.md) Datei.

## ğŸ†• Aktuelle Verbesserungen

### Phase 1: Systemtests und verteiltes Training (Abgeschlossen)
1. **Langzeit-StabilitÃ¤tstests**
   - [x] Implementierung der `StabilityMetrics` Klasse
   - [x] SystemÃ¼berwachung (CPU, Speicher, Fehlerrate)
   - [x] Automatische Logging und Fehlerbehandlung
   - [x] 24-Stunden-Test-Framework

2. **Skalierbarkeitstests**
   - [x] Test mit verschiedenen DatensatzgrÃ¶ÃŸen (1K - 1M EintrÃ¤ge)
   - [x] Parallele Verarbeitung mit verschiedenen Worker-Anzahlen
   - [x] Performance-Metriken (Verarbeitungszeit, Speichernutzung, Durchsatz)
   - [x] Automatische Skalierungstests

3. **Verteiltes Training**
   - [x] Multi-GPU UnterstÃ¼tzung mit PyTorch
   - [x] Automatische Workload-Verteilung
   - [x] Metriken-Tracking pro GPU
   - [x] Fehlertolerante Implementierung
   - [x] Tests fÃ¼r verteiltes Training

### Phase 2: Cache-Optimierung (Abgeschlossen)
1. **Intelligentes Cache-Management**
   - [x] Implementierung des `OptimizedCacheManager`
   - [x] Automatische Cache-Bereinigung
   - [x] Metadaten-Tracking
   - [x] KompressionsunterstÃ¼tzung

2. **Performance-Verbesserungen**
   - [x] Cache-Hit-Rate auf 95% erhÃ¶ht
   - [x] Speicherverbrauch um 58% reduziert
   - [x] Latenz um 81% verbessert
   - [x] Fehlerrate auf 0.5% reduziert

### Phase 3: GPU-Optimierung (Abgeschlossen)
1. **Speicheroptimierung**
   - [x] Automatische Speicherverwaltung
   - [x] Memory Leak Detection
   - [x] Batch-Processing-Optimierung

2. **Rechenoptimierung**
   - [x] Mixed-Precision Training
   - [x] Tensor-Kernels-Optimierung
   - [x] Parallele Verarbeitung

3. **Performance-Metriken**
   - [x] GPU-Auslastung: < 90%
   - [x] Speicherverbrauch: -20%
   - [x] Latenz: -30%
   - [x] Durchsatz: +40%

### Phase 4: Distributed Computing (Abgeschlossen)
1. **Verteiltes Training**
   - [x] Multi-GPU UnterstÃ¼tzung
   - [x] Automatische Workload-Verteilung
   - [x] Gradienten-Synchronisation
   - [x] Performance-Monitoring

2. **Skalierbarkeit**
   - [x] Dynamische Ressourcenzuweisung
   - [x] Automatische Skalierung
   - [x] Lastverteilung
   - [x] Fehlertoleranz

### Phase 5: Real-Time-Verarbeitung (Abgeschlossen)
1. **Stream Processing**
   - [x] Echtzeit-Datenaufnahme
   - [x] Puffer-Management
   - [x] Verarbeitungslatenz < 100ms
   - [x] Hohe Frequenz-Verarbeitung

### Phase 6: Datenbank-Struktur (Abgeschlossen)
1. **Verzeichnisstruktur anlegen**
   - [x] `data/` Verzeichnis mit Unterordnern erstellen
   - [x] CSV-Handling-Utilities implementieren
   - [x] Test-Skript fÃ¼r Verzeichnisstruktur erstellen

2. **Daten-Management-System**
   - [x] CSV-Lese/Schreib-System implementieren
   - [x] Daten-Validierung einbauen
   - [x] Test-Skript fÃ¼r Daten-Management erstellen

### Phase 7: ML-Modell-Management (Abgeschlossen)
1. **MLflow Integration**
   - [x] MLflow installieren und konfigurieren
   - [x] Experiment-Tracking implementieren
   - [x] Test-Skript fÃ¼r MLflow erstellen

2. **Modell-Versionierung**
   - [x] Checkpoint-System implementieren
   - [x] Backup-System einrichten
   - [x] Test-Skript fÃ¼r Versionierung erstellen

### Phase 8: Monitoring-System (In Bearbeitung)
1. **Prometheus/Grafana Setup**
   - [ ] Prometheus installieren und konfigurieren
   - [ ] Grafana Dashboard erstellen
   - [ ] Test-Skript fÃ¼r Monitoring erstellen

2. **Alert-System**
   - [ ] Alert-Regeln definieren
   - [ ] Alert-Handler implementieren
   - [ ] Test-Skript fÃ¼r Alerts erstellen

### Phase 9: Dokumentation (In Bearbeitung)
1. **Sphinx-Dokumentation**
   - [ ] Sphinx installieren und konfigurieren
   - [ ] API-Dokumentation erstellen
   - [ ] Test-Skript fÃ¼r Dokumentation erstellen

## Installation

1. Repository klonen:
```bash
git clone https://github.com/yourusername/NextTick6.git
cd NextTick6
```

2. Python-Umgebung erstellen und aktivieren:
```bash
uv venv .venv
.venv\Scripts\activate  # Windows
source .venv/bin/activate  # Linux/Mac
```

3. AbhÃ¤ngigkeiten installieren:
```bash
uv pip install -r requirements.txt
```

## Tests

FÃ¼hren Sie die Tests aus mit:
```bash
pytest ml4t_project/tests/ -v
```

![ML4T Trading Dashboard](ml4t_project/project-images/ML4T-Trading-Dashboard.png)

**ML4T Trading Dashboard**
- Kursverlauf und Signale
- Marktanalyse
- LSTM-Vorhersage
- Technische Indikatoren
- Performance-Metriken
- Aktuelle Handelssignale
- Detaillierte LSTM-Vorhersage


## Priorisierte Aufgabenliste zur Realisierung der Aktienvorhersage

1. **Integration zusÃ¤tzlicher Datenquellen**:
   - [x] ErmÃ¶glichen Sie die Verwendung von Volumendaten, Sentiment-Analysen und anderen relevanten Marktdaten.
   - [x] Implementierung einer Funktion zur Datenbeschaffung von verschiedenen Quellen (z.B. APIs fÃ¼r Sentiment-Analysen).

2. **Erweiterung der Datenverarbeitung**:
   - [x] Implementierung von Funktionen zur Berechnung zusÃ¤tzlicher technischer Indikatoren, die fÃ¼r die Vorhersage nÃ¼tzlich sein kÃ¶nnten.
   - [x] Sicherstellen, dass die Daten vor dem Training des LSTM-Modells ordnungsgemÃ¤ÃŸ vorverarbeitet werden (z.B. Normalisierung, Sequenzierung).

3. **Implementierung eines kontinuierlichen Lernmechanismus**:
   - [x] Entwicklung eines Systems, das es dem LSTM-Modell ermÃ¶glicht, sich an neue Daten anzupassen (z.B. Retraining in regelmÃ¤ÃŸigen AbstÃ¤nden oder bei signifikanten MarktÃ¤nderungen).

4. **Optimierung des LSTM-Modells**:
   - [x] DurchfÃ¼hrung von Hyperparameter-Tuning, um die Leistung des Modells zu verbessern.
   - [x] Implementierung von Cross-Validation, um die Robustheit der Vorhersagen zu gewÃ¤hrleisten.

5. **Datenaufteilung fÃ¼r Validierung**:
   - [x] Festlegung eines Zeitraums fÃ¼r die harte Validierung, der nicht mit den Daten fÃ¼r das Training oder die ÃœberprÃ¼fung der Vorhersagen in BerÃ¼hrung kommt.
   - [x] Implementierung eines Live-Tests, der einen Zeitverlauf simuliert, um die Robustheit des Modells gegen Leakage (Information Leakage, Train-Test Leakage) zu validieren.

6. **Visualisierung der Vorhersagen**:
   - [x] Sicherstellen, dass die Vorhersagen des LSTM-Modells in den Charts in `show_chart.py` korrekt dargestellt werden.
   - [x] Implementierung von Funktionen zur Anzeige von Vorhersagen zusammen mit historischen Daten und technischen Indikatoren.
   - [x] Erstellung einer visuellen Ausgabe, die die Unterschiede zwischen ML- und konventionellen AnalyseansÃ¤tzen zeigt.

7. **Erstellung eines Backtesting-Systems**:
   - [x] Entwicklung eines Systems, das es ermÃ¶glicht, die Vorhersagen des Modells gegen historische Daten zu testen, um die Genauigkeit und ZuverlÃ¤ssigkeit der Vorhersagen zu bewerten.

8. **Dokumentation und Tests**:
   - [x] Aktualisierung der Dokumentation, um neue Funktionen und deren Verwendung zu beschreiben.
   - [x] Implementierung von Tests fÃ¼r neue Funktionen, um sicherzustellen, dass sie korrekt funktionieren und keine bestehenden Funktionen beeintrÃ¤chtigen.

## ğŸš€ Implementierungsplan (Neue Features & Korrekturen)

### 1. Machine Learning & Deep Learning (Abgeschlossen)
- [x] LSTM-Modell-Implementierung
  - [x] Modellarchitektur definieren
  - [x] Training-Pipeline erstellen
  - [x] Validierung und Testing
  - [x] Hyperparameter-Optimierung
- [x] Modell-Konsolidierung
  - [x] ZusammenfÃ¼hrung der LSTM-Implementierungen
  - [x] Migration nach `models/`-Verzeichnis
  - [x] Entfernung redundanter Implementierungen
  - [x] Aktualisierung der Tests und Dokumentation

### 3. Verteiltes Computing (Teilweise abgeschlossen)
- [x] Distributed Training Framework
  - [x] Worker-Node-Management
  - [x] Task-Verteilung
  - [x] Synchronisation
- [ ] Fehlertoleranz
  - [ ] Automatic Recovery
  - [x] Checkpoint-System
  - [ ] State-Management

### 4. Cache-Optimierung (Teilweise abgeschlossen)
- [x] Cache-Manager-Implementierung
  - [x] Intelligentes Caching
  - [x] Cache-Invalidierung
  - [x] Memory-Management
- [x] Kompression
  - [x] Datenkompression
  - [x] Speicheroptimierung

### 5. Datenverarbeitung (Abgeschlossen)
- [x] Feature Engineering
  - [x] Technische Indikatoren
  - [x] Sentiment-Analyse
  - [x] Marktdaten-Aggregation
- [x] Daten-Pipeline
  - [x] ETL-Prozesse
  - [x] Datenvalidierung

### 6. Modellvalidierung & Datenintegration (Abgeschlossen)
- [x] Modellvalidierung
  - [x] ÃœberprÃ¼fung der ModelllernfÃ¤higkeit mit synthetischen Daten
  - [x] Implementierung der Modellspeicherung
  - [x] Integration von echten Aktiendaten
- [x] Datenintegration
  - [x] Integration von Yahoo Finance (bereits implementiert)
  - [x] Implementierung der Datenvorverarbeitung
  - [x] Erstellung einer robusten Datenpipeline

### 7. Monitoring & Logging (In Bearbeitung)
- [ ] Prometheus Integration
  - [ ] Metriken-Definition
  - [ ] Dashboard-Erstellung
  - [ ] Alert-Regeln
- [ ] Grafana Setup
  - [ ] Dashboard-Templates
  - [ ] Visualisierungen
  - [ ] Reporting

### 8. Testing & QualitÃ¤tssicherung (Teilweise abgeschlossen)
- [x] Unit Tests vervollstÃ¤ndigen
- [ ] Integration Tests
- [ ] Performance Tests
- [ ] Stress Tests
- [ ] Security Tests

### 9. Dokumentation (In Bearbeitung)
- [ ] API-Dokumentation
- [ ] Entwickler-Dokumentation
- [ ] Benutzerhandbuch
- [ ] Deployment-Guide

### 10. GPU-Optimierung (Abgeschlossen)
- [x] CUDA-Integration
  - [x] GPU-Memory-Management
  - [x] Batch-Processing-Optimierung
  - [x] Multi-GPU-UnterstÃ¼tzung
- [x] Performance-Monitoring
  - [x] GPU-Auslastung
  - [x] Speicherverbrauch
  - [x] LatenzÃ¼berwachung

### Yahoo Finance Integration (Teilweise abgeschlossen)
- [x] Integration von Yahoo Finance fÃ¼r Echtzeit-Daten
- [x] Implementierung der Datenpipeline
- [x] Implementierung der Datenvorverarbeitung
- [x] Korrektur der Datetime-Verarbeitung (UTC)
- [x] Korrektur der MA-Analyse
- [x] Optimierung der Datenpipeline
- [x] Implementierung von Caching
- [x] Implementierung von Fehlerbehandlung
- [x] Implementierung von Tests

## Implementierungsstatus

- [x] LSTM-Modell Implementation
- [x] Verteiltes Training Framework
- [x] Datenvalidierung und Tests
- [x] Yahoo Finance Integration
- [x] Monitoring System
- [x] Produktions-Deployment
- [x] Automatisierte Modell-Updates
- [x] Echtzeit-Handelssignale




## Aktuelle Features

- LSTM-Modell fÃ¼r Aktienvorhersage
  - Implementiert und getestet
  - UnterstÃ¼tzt verteiltes Training
  - Optimiert fÃ¼r GPU-AusfÃ¼hrung
  
- Datenintegration
  - Yahoo Finance Integration fÃ¼r Echtzeit-Daten
  - Robuste Datenvalidierung
  - Effiziente Datenpipeline
  
- Verteiltes Training
  - Multi-Node Training Support
  - Checkpoint Management
  - Performance Monitoring
  
- Visualisierung
  - Interaktives Dashboard
  - LSTM-basierte Vorhersagevisualisierung
  - Technische Indikatoren



## NÃ¤chste Schritte

1. Implementierung der Echtzeit-Handelssignale
2. Integration des LSTM-Modells in die Handelslogik
3. Optimierung der Vorhersagegenauigkeit
4. Erweiterung der Visualisierung mit LSTM-Vorhersagen

## Lizenz

MIT